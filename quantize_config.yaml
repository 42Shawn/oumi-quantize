# Sample Quantization Configuration
# ðŸš§ DEVELOPMENT: This configuration tests the quantization interface

# Model configuration
model:
  model_name: "meta-llama/Llama-2-7b-hf"
  tokenizer_name: "meta-llama/Llama-2-7b-hf"

# Quantization settings
method: "q4_0"                    # 4-bit quantization
output_path: "llama2-7b-q4.gguf"  # Output file path
output_format: "gguf"             # GGUF format

# Optional settings
verbose: true                     # Enable detailed logging
